\chapter{Introduction}

Microscopy of biological specimens is used in biotechnology to
visualize small specimens (including their internal structures) that
cannot be seen with the naked eye. For this, some kind of interaction
between the specimens and a source of energy must exist (the specimen
must be irradiated), an action that usually degrades the specimen and
for this reason, the radiation is minimized generating low SNR
images. In this report, we describe, evaluate, and compare several
image denoising algorithms commonly used in microscopy of biological
specimens.

\section{Image acquisition in microscopy}
%{{{

There are several tecniques to capture microscopy images:

\begin{enumerate}
  \item \textbf{\gls{LM}}: Light passes through the specimen, and this light
  is then magnified by an objective and ocular lenses to form an
  observable image. Fluorescence microscopy and confocal microscopy
  are two \gls{LM} tecniques, where the specimen(s) emit light after
  have being excited by a source of light. Using \gls{LM} we can
  typical reach a resolution of up to 200 nm.

\item \textbf{\gls{EM}}: We use a beam of electrons that can pass through the
  sample (\gls{TEM}) or bounce on the sample (\gls{SEM}). X-rays and
  ions can also be used (the smaller the wavelength of the radiation,
  the higher the resolution). In general, compared to \gls{LM},
  \gls{EM} allows much higher resolution (down to sub-nanometer
  scale).

\item \textbf{\gls{SPM}}: A nano-scale mechanical probe maps the surface of a
  specimen. \gls{SPM} achieves sub-nanometer resolution, allowing for
  the imaging of surfaces at the atomic scale. The \gls{AFM} and the
  \gls{STM} are \gls{SPM} techniques.
\end{enumerate}
  
%}}}

\section{Tomography}
%{{{

Tomography refers to the computational reconstruction of 3D volumes
from a series of 2D projections. Depending on the imaging modalities
we can distinguish bewtween:
\begin{enumerate}
\item \textbf{\gls{ET}}: Used mainly in cell biology and materials
  science. The samples are usually resin-embedded. Achieve resolutions
  btween 1 and 10 nm.
\item \textbf{\gls{cryo-ET}}: Used in structural
  biology (e.g., visualizing viruses, ribosomes, organelles). The
  samples are usually frozen-hydrated. Achieven resolutions between 3
  and 5 nm.
\item \textbf{\gls{OPT}}: Usually based in
  light microscopy, OPT is a non-destructive 3D imaging technique used
  to observe transparent samples like embryos or organoids. The
  typical resolutions range between 5 and 50 $\mu$m.
\item \textbf{Fluorescence Tomography}: Used to mapping 3D
  fluorescence distribution in tissues, often for molecular imaging in
  live animals or cleared tissues. Resolution ranges between 10 and
  100 $\mu$m.
\item \textbf{\gls{SXT}}: 3D imaging of intact cells with
  higher penetration than electrons or light. Resolution between 30
  and 50 nm.
\item \textbf{\gls{PAT}}: Light excitation + ultrasound
  detection. Used in deep-tissue imaging of functional contrast (like
  blood oxygenation) in live animals. Resolution between 50 and 300
  $\mu$m.
\end{enumerate}

Therefore, a tomogram is a 3D digital signal (volume) generated by a
tomography technique.

%}}}

\section{Noise in microscopy}
%{{{

In microscopy imaging there are three main sources of noise: (1)
\emph{dark noise} which corresponds to the electronic noise generated
by the thermal agitation of electrons, (2) \emph{photon noise} (or
shot noise) that is generated by the fluctuations in the number of
photons sensed at a given signal exposure level, and (3) the
\emph{read-out noise}, generated by the non-perfectness of the output
electronic amplifiers used in the process of converting photon or
electron accumulations into voltages. Therefore, the level of noise
depends on the exposure time and experimental conditions affecting the
sensors such as temperature, among other capturing parameters. Dark
and photon noises are usually modeled as a Poisson distribution
$\mathcal{P}(\lambda)$, where $\lambda$ represents the average dark
flux. Typically, read-out noise is modeled as zero-mean additive white Gaussian
noise \cite{meiniel2018denoising,zhou2020wirtinger}.

%}}}

\section{Why denoising?}
\label{sec:why_denoising}
%{{{

%We consider denoising techniques where there is only one noisy
%instance or a few instances, usually in the latter case with slightly
%different versions of the clean signal. Averaging as such is therefore
%excluded.

In general, when we study biological samples, the impact of the
ratiation of generated by the microscope can degrade it. To minimize
this degradation, the radiation doses are minimized, generating low
\gls{SNR} images which require the use of denoising algorithms to
facilitate subsequent analysis. An optimal denoiser should
effectively attenuate noise while concurrently preserving crucial
image features, including edges, textures, and underlying biological
structures.

An added challenge to this situation is the limited availability of
only a single noisy realization of these images, which complicates
both the evaluation of denoising algorithms (due to the absence of a
ground truth for comparative assessment) and the selection of
appropriate denoising parameters. 

%}}}

