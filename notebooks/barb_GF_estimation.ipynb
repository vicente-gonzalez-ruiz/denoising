{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "QqfKxC0KuCzK",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Optimal GF for barb\n",
    "\n",
    "1. Determine the frequency $u$ for which the average FSC progressively computed from the normalized frequency 0.5 is higher than some given threshold $t=0.143$, by default.\n",
    "2. Compute the corresponding Gaussian filter length $\\tau$ whose cut-off frequency is $u$.\n",
    "3. Filter the image.\n",
    "\n",
    "Hay que estudiar:\n",
    "1. Si el valle en la curva SFRC es culpa del filtro separable (comparar con el 2D puro). No es culpa. Por encima de la frecuencia normalizada 0.25 la SFRC no es significativa.\n",
    "2. Si usando random shuffling y OF es posible obtener una SFRC mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IIUxh4uStrQJ"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import namedtuple\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "except:\n",
    "    !pip install numpy\n",
    "    import numpy as np\n",
    "\n",
    "import scipy.ndimage\n",
    "\n",
    "try:\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.ticker as mticker\n",
    "except:\n",
    "    !pip install matplotlib\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.ticker as mticker\n",
    "\n",
    "try:\n",
    "    from skimage import io as skimage_io\n",
    "except:\n",
    "    !pip install scikit-image\n",
    "    from skimage import io as skimage_io\n",
    "\n",
    "try:\n",
    "    import information_theory as IT\n",
    "except:\n",
    "    !pip install \"information_theory @ git+https://github.com/vicente-gonzalez-ruiz/information_theory\"\n",
    "    import information_theory as IT\n",
    "\n",
    "import utils        #freq, c_avg = fsc.get_SFRC_curve(denoised)\n",
    "        #first_half = c_avg[:len(c_avg)>>1]\n",
    "        #SFRC_curve.append(first_half)\n",
    "        #plt.imshow(denoised, cmap=\"gray\")\n",
    "        #plt.show()\n",
    "        #input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apt install cm-super-minimal\n",
    "# apt install dvipng\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    #\"font.family\": \"Helvetica\",\n",
    "    \"font.family\": \"Serif\",\n",
    "    \"text.latex.preamble\": r\"\\usepackage{amsmath} \\usepackage{amsfonts}\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format=\"[%(filename)s:%(lineno)s %(funcName)s()] %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from self_fourier_shell_correlation import fsc_utils as fsc\n",
    "except:\n",
    "    !pip install \"self_fourier_shell_correlation @ git+https://github.com/vicente-gonzalez-ruiz/self_fourier_shell_correlation\"\n",
    "    from self_fourier_shell_correlation import fsc_utils as fsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import denoising.image.gaussian as denoising\n",
    "except:\n",
    "    !pip install \"denoising @ git+https://github.com/vicente-gonzalez-ruiz/denoising\"\n",
    "    import denoising.image.gaussian as denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoiser = denoising.Monochrome_Denoising(logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Args = namedtuple(\"args\", [\"input\"])\n",
    "#args = Args(\"barb_0MMPG.png\")\n",
    "Args = namedtuple(\"args\", [\"X\", \"Y\"])\n",
    "args = Args(\"http://www.hpca.ual.es/~vruiz/images/barb.png\", \"barb_0MMPG.png\")\n",
    "#args = Args(\"http://www.hpca.ual.es/~vruiz/images/lake.png\", \"lake_0MMPG.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = skimage_io.imread(args.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    Y = skimage_io.imread(args.Y)\n",
    "except FileNotFoundError:\n",
    "    %run barb_0MMPG.ipynb\n",
    "    Y = skimage_io.imread(args.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.imshow(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.imshow(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute SFRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_1, c_avg_Y_1 = fsc.get_SFRC_curve__even_odd(X)\n",
    "freq_2, c_avg_Y_2 = fsc.get_SFRC_curve__even_odd(Y)\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "plt.plot(freq_1, c_avg_Y_1, label=\"X\")\n",
    "filtered_c_avg_Y_1 = gaussian_filter1d(c_avg_Y_1, sigma=5)\n",
    "plt.plot(freq_1, filtered_c_avg_Y_1)\n",
    "\n",
    "plt.plot(freq_2, c_avg_Y_2, label=\"Y\")\n",
    "filtered_c_avg_Y_2 = gaussian_filter1d(c_avg_Y_2, sigma=5)\n",
    "plt.plot(freq_2, filtered_c_avg_Y_2)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_1, c_avg_Y_1 = fsc.get_SFRC_curve__random_shuffling(X)\n",
    "freq_2, c_avg_Y_2 = fsc.get_SFRC_curve__random_shuffling(Y)\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "plt.plot(freq_1, c_avg_Y_1, label=\"X\")\n",
    "filtered_c_avg_Y_1 = gaussian_filter1d(c_avg_Y_1, sigma=5)\n",
    "plt.plot(freq_1, filtered_c_avg_Y_1)\n",
    "\n",
    "plt.plot(freq_2, c_avg_Y_2, label=\"Y\")\n",
    "filtered_c_avg_Y_2 = gaussian_filter1d(c_avg_Y_2, sigma=5)\n",
    "plt.plot(freq_2, filtered_c_avg_Y_2)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_noise(signal):\n",
    "    noise_estimation = signal[len(signal)-1]\n",
    "    return noise_estimation\n",
    "    \n",
    "def find_cutoff_freq(image, beta=0.1, sigma=5):\n",
    "    freq, c_avg = fsc.get_SFRC_curve__random_shuffling(image)\n",
    "    #freq, c_avg = fsc.get_SFRC_curve__even_odd(image)\n",
    "    filtered_c_avg = gaussian_filter1d(c_avg, sigma)\n",
    "    noise_estimation = estimate_noise(filtered_c_avg)\n",
    "    cutoff_idx = np.where(filtered_c_avg < filtered_c_avg[0] * beta)[0][0]\n",
    "    #cutoff_idx = np.where(filtered_c_avg < noise_estimation ** beta )[0][0]\n",
    "    #noise_estimation = estimate_noise(filtered_c_avg); cutoff_idx = np.where(filtered_c_avg < noise_estimation + beta)[0][0]\n",
    "    cutoff_freq = freq[cutoff_idx]\n",
    "    return cutoff_freq\n",
    "\n",
    "eta_X = find_cutoff_freq(X)\n",
    "eta_Y = find_cutoff_freq(Y)\n",
    "print(eta_X)\n",
    "print(eta_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tau(eta):\n",
    "    return 0.141/eta\n",
    "\n",
    "tau_X = find_tau(eta_X)\n",
    "tau_Y = find_tau(eta_Y)\n",
    "print(tau_X)\n",
    "print(tau_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### barb_GF_estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_devs = [i for i in range(0, 100, 20)]\n",
    "PCC_curves = []\n",
    "poisson_ratio = 0.5\n",
    "gamma = 0.15\n",
    "for std_dev in std_devs: # Number of noise levels\n",
    "    PCC_curve = []\n",
    "    Y = utils.generate_MPGN(X, std_dev, gamma, poisson_ratio).reshape(X.shape)\n",
    "    eta = find_cutoff_freq(Y)\n",
    "    tau = find_tau(eta)\n",
    "    sigma = np.array([tau, tau])\n",
    "    kernel = [None]*2\n",
    "    kernel[0] = utils.get_gaussian_kernel(tau)\n",
    "    kernel[1] = utils.get_gaussian_kernel(tau)\n",
    "    denoised = denoiser.filter(Y, kernel)\n",
    "    print(\"std_dev =\", std_dev, \"tau =\", tau)\n",
    "    freq, c_avg = fsc.get_SFRC_curve__random_shuffling(denoised)\n",
    "    plt.plot(freq, c_avg, label=f\"tau={tau}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = [None]*2\n",
    "kernel[0] = utils.get_gaussian_kernel(tau_Y*2)\n",
    "kernel[1] = utils.get_gaussian_kernel(tau_Y*2)\n",
    "Z = denoiser.filter(Y, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_threshold_index(signal, threshold):\n",
    "    return np.searchsorted(-signal, -threshold, side='left')\n",
    "\n",
    "freq_index_threshold = find_threshold_index(filtered_c_avg_Y, threshold=0.2)/freq.size/2\n",
    "print(freq_index_threshold, freq.size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_cutoff_to_tau(cutoff_freq):\n",
    "    tau = 0.158 / cutoff_freq\n",
    "    return tau\n",
    "\n",
    "tau = normalized_cutoff_to_tau(freq_index_threshold)\n",
    "print(tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taus = [(0.2 + i/40) for i in range(40)] # Number of points per line\n",
    "std_devs = [i for i in range(0, 100, 20)]\n",
    "PCC_curves = []\n",
    "SFRC_curves = []\n",
    "poisson_ratio = 0.5\n",
    "gamma = 0.15\n",
    "for std_dev in std_devs: # Number of noise levels\n",
    "    #gamma = std_dev / 50\n",
    "    PCC_curve = []\n",
    "    SFRC_curve = []\n",
    "    Y = utils.generate_MPGN(X, std_dev, gamma, poisson_ratio).reshape(X.shape)\n",
    "    #Y = np.clip(a = Y, a_min=0, a_max=255) # Probar a quitar\n",
    "    #for sigma_kernel in range(5, 20, 1):\n",
    "    for tau in taus: # Filter length\n",
    "        #sigma_kernel /= 10\n",
    "        sigma = np.array([tau, tau])\n",
    "        kernel = [None]*2\n",
    "        kernel[0] = utils.get_gaussian_kernel(sigma[0])\n",
    "        kernel[1] = utils.get_gaussian_kernel(sigma[1])\n",
    "        #print(\"Kernel:\", kernel)\n",
    "        denoised = denoiser.filter(Y, kernel)\n",
    "        #PSNR = IT.distortion.PSNR(denoised, X)\n",
    "        PCC = np.corrcoef(denoised.flatten(), X.flatten())[0, 1]\n",
    "        print(\"std_dev:\", std_dev, \"sigma_kernel:\", tau, \"PCC:\", PCC)\n",
    "        PCC_curve.append(PCC)\n",
    "        #freq, c_avg = fsc.get_SFRC_curve(denoised)\n",
    "        #first_half = c_avg[:len(c_avg)>>1]\n",
    "        #SFRC_curve.append(first_half)\n",
    "        #plt.imshow(denoised, cmap=\"gray\")\n",
    "        #plt.show()\n",
    "        #input()\n",
    "\n",
    "    PCC_curves.append(PCC_curve)\n",
    "    #SFRC_curves.append(SFRC_curve)\n",
    "    \n",
    "    #sigma_index += 1\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.title(r\"$\\mathbf{X}=\\mathrm{Barb}$\")\n",
    "#plt.title(r\"$\\mathbb{E}_{\\text{\" + str(iters) + r\"}}(\\mathbf{N}\" + rf\"/{_lambda}\" + r\"), \\mathbf{N}\\sim\\mathrm{Poisson}\" + rf\"(\\lambda={_lambda}\" + r\"\\mathrm{Barb})$\")\n",
    "#plt.title(\"Averaging Poisson noisy instances of \\\"Barb\\\"\")\n",
    "#for i in range(len(curves)):\n",
    "i = 0\n",
    "for std_dev in std_devs:\n",
    "    #plt.plot([i/10 for i in range(5, 20, 1)], curves[i], label=rf\"$\\sigma={10+i*5}, \\lambda={(10-i)/40}\\cdot\" + r\"\\mathrm{Barb}$\")\n",
    "    #if ((10+i*5) == 40) and ((10-i)/40 == 0.15):\n",
    "    #plt.plot(sigmas_kernel, curves[i], label=rf\"$\\sigma={10+i*5}, \\gamma={(10-i)/40}\" + r\", \\mathrm{argmax}_\\tau=\" + rf\"{sigmas_kernel[np.argmax(curves[i])]:.2f}$\", marker='o')\n",
    "    #else:\n",
    "    plt.plot(taus,\n",
    "        PCC_curves[i],\n",
    "        label=rf\"$\\sigma={std_dev}, \\gamma={gamma}\"\n",
    "        + r\", \\tau^*=\"\n",
    "        + rf\"{taus[np.argmax(PCC_curves[i])]:.2f}\"\n",
    "        + \"$\")\n",
    "    i += 1\n",
    "string  = r\"$\"\n",
    "string += r\"\\mathrm{PCC}\"\n",
    "string += r\"(\\mathbf{X}, \"\n",
    "string += r\"\\mathrm{GF}_\\tau\"\n",
    "string += r\"(\\hat{\\mathbf{X}}\"\n",
    "#string += r\"+ \\mathbf{N}_{\\mathcal{N}\"\n",
    "#string += r\"(\\sigma)}\"\n",
    "#string += r\"+ \\mathbf{N}_\"\n",
    "#string += r\"{\\mathcal{P}(\\gamma\\mathbf{X})}/\\gamma))$\"\n",
    "string += r\"))$\"\n",
    "plt.ylabel(string)\n",
    "#plt.ylabel(r\"$\\mathrm{PCC}(\\mathbf{X}, \\hat{\\mathbf{X}})$\")\n",
    "plt.xlabel(r\"$\\tau$\")\n",
    "plt.legend()\n",
    "#plt.show()\n",
    "plt.savefig(\"barb_GF_optimal.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_lowpass_filter(shape, normalized_cutoff):\n",
    "    \"\"\"Creates a Gaussian low-pass filter in the frequency domain using normalized frequency.\"\"\"\n",
    "    rows, cols = shape\n",
    "    N = min(rows, cols)  # Assume square image size for cutoff scaling\n",
    "\n",
    "    # Convert normalized frequency to pixel-based cutoff\n",
    "    cutoff_px = (normalized_cutoff * N) / 2  \n",
    "\n",
    "    # Create frequency coordinate grids\n",
    "    u = np.arange(-cols//2, cols//2)\n",
    "    v = np.arange(-rows//2, rows//2)\n",
    "    U, V = np.meshgrid(u, v)\n",
    "\n",
    "    # Compute Gaussian filter\n",
    "    D = np.sqrt(U**2 + V**2)  # Distance from center\n",
    "    H = np.exp(-(D**2) / (2 * (cutoff_px**2)))  # Gaussian function\n",
    "\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = np.fft.fft2(Y)\n",
    "dft_shift = np.fft.fftshift(dft)\n",
    "\n",
    "normalized_cutoff = 0.1  # Adjust this value as needed\n",
    "\n",
    "# Generate Gaussian filter\n",
    "H = gaussian_lowpass_filter(Y.shape, normalized_cutoff)\n",
    "magnitude_spectrum = np.log(1 + np.abs(dft_shift))\n",
    "plt.imshow(magnitude_spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(H)\n",
    "\n",
    "# Apply the filter\n",
    "filtered_dft = dft_shift * H\n",
    "\n",
    "# Inverse Fourier Transform\n",
    "dft_inverse = np.fft.ifftshift(filtered_dft)\n",
    "image_filtered = np.fft.ifft2(dft_inverse)\n",
    "image_filtered = np.abs(image_filtered)\n",
    "\n",
    "# Display results\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1), plt.imshow(utils.clip(Y), cmap='gray'), plt.title('Original Image')\n",
    "plt.subplot(1,2,2), plt.imshow(utils.clip(image_filtered), cmap='gray'), plt.title(f'Filtered (Normalized Cutoff={normalized_cutoff})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq, c_avg_image_filtered = fsc.get_SFRC_curve(image_filtered)\n",
    "plt.plot(freq, c_avg_image_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separable 2D filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.ones_like(X)*255\n",
    "tau = 20.5\n",
    "sigma = np.array([tau, tau])\n",
    "kernel = [None]*2\n",
    "kernel[0] = utils.get_gaussian_kernel(sigma[0])\n",
    "kernel[1] = utils.get_gaussian_kernel(sigma[1])\n",
    "\n",
    "# Create 2D separable Gaussian kernel\n",
    "gaussian_2d = np.outer(kernel[0], kernel[1])\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(gaussian_2d, cmap='viridis', interpolation='nearest')\n",
    "plt.colorbar(label=\"Intensity\")\n",
    "plt.title(\"2D Gaussian Kernel (Separable)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot separable Gaussian (in the Fourier domain)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define parameters\n",
    "sigma = 0.03  # Adjust as needed\n",
    "size = 256     # Grid size\n",
    "\n",
    "# Create grid\n",
    "u = np.linspace(-100, 100, size)\n",
    "v = np.linspace(-100, 100, size)\n",
    "U, V = np.meshgrid(u, v)\n",
    "\n",
    "# Compute function\n",
    "Z = np.exp(- (U**2 / (2 * sigma**-2))) * np.exp(- (V**2 / (2 * sigma**-2)))\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(Z, cmap='viridis', extent=[-10, 10, -10, 10], origin='lower')\n",
    "plt.colorbar(label=\"Intensity\")\n",
    "plt.title(r\"$e^{-\\frac{u^2}{2\\sigma^{-2}}} e^{-\\frac{v^2}{2\\sigma^{-2}}}$ Heatmap\")\n",
    "plt.xlabel(\"u\")\n",
    "plt.ylabel(\"v\")\n",
    "plt.show()\n",
    "\n",
    "# 3D Surface plot\n",
    "fig = plt.figure(figsize=(7, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(U, V, Z, cmap='viridis')\n",
    "ax.set_title(r\"3D Surface of $e^{-\\frac{u^2}{2\\sigma^{-2}}} e^{-\\frac{v^2}{2\\sigma^{-2}}}$\")\n",
    "ax.set_xlabel(\"u\")\n",
    "ax.set_ylabel(\"v\")\n",
    "ax.set_zlabel(\"Value\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot true 2D Gaussian (in the Fourier domain)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define parameters\n",
    "sigma = 0.03  # Adjust as needed\n",
    "size = 256     # Grid size\n",
    "\n",
    "# Create grid\n",
    "u = np.linspace(-100, 100, size)\n",
    "v = np.linspace(-100, 100, size)\n",
    "U, V = np.meshgrid(u, v)\n",
    "\n",
    "# Compute function\n",
    "Z = np.exp(- (U**2 + V**2) / (2 * sigma**-2))\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(Z, cmap='viridis', extent=[-10, 10, -10, 10], origin='lower')\n",
    "plt.colorbar(label=\"Intensity\")\n",
    "plt.title(r\"$e^{-\\frac{u^2}{2\\sigma^{-2}}} e^{-\\frac{v^2}{2\\sigma^{-2}}}$ Heatmap\")\n",
    "plt.xlabel(\"u\")\n",
    "plt.ylabel(\"v\")\n",
    "plt.show()\n",
    "\n",
    "# 3D Surface plot\n",
    "fig = plt.figure(figsize=(7, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(U, V, Z, cmap='viridis')\n",
    "ax.set_title(r\"3D Surface of $e^{-\\frac{u^2}{2\\sigma^{-2}}} e^{-\\frac{v^2}{2\\sigma^{-2}}}$\")\n",
    "ax.set_xlabel(\"u\")\n",
    "ax.set_ylabel(\"v\")\n",
    "ax.set_zlabel(\"Value\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised = denoiser.filter(ones, kernel)\n",
    "print(np.max(denoised), np.min(denoised))\n",
    "dft = np.fft.fft2(denoised)\n",
    "dft_shift = np.fft.fftshift(dft)\n",
    "magnitude_spectrum = np.log(1 + np.abs(dft_shift))\n",
    "# plt.imshow(magnitude_spectrum)\n",
    "plt.imshow(denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special case for displaying\n",
    "\n",
    "gamma = 0.15\n",
    "std_dev = 40\n",
    "acc_denoised = np.zeros_like(X, dtype=np.float64)\n",
    "iters = 1\n",
    "PSNR = 1\n",
    "while PSNR < min_PSNR:\n",
    "    Y = utils.generate_MPGN(X, std_dev, gamma)\n",
    "    #Y = np.clip(a = Y, a_min=0, a_max=255)\n",
    "    Y = Y.astype(np.uint8)\n",
    "    acc_denoised += Y\n",
    "    denoised = acc_denoised/iters\n",
    "    PSNR = IT.distortion.PSNR(denoised.astype(np.uint8), X)\n",
    "    iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_cutoff_to_tau(cutoff_freq, img_shape):\n",
    "    N = min(img_shape)\n",
    "    tau = 1 / (2 * np.pi * cutoff_freq * (N / 2))\n",
    "    return tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = normalized_cutoff_to_tau(0.25, Y.shape)\n",
    "tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_gaussian_kernel(sigma=1):\n",
    "    \"\"\"Generates a 1D Gaussian kernel using scipy.ndimage.gaussian_filter1d().\"\"\"\n",
    "    number_of_coeffs = 3\n",
    "    number_of_zeros = 0\n",
    "    while number_of_zeros < 2:\n",
    "        delta = np.zeros(number_of_coeffs)\n",
    "        delta[delta.size // 2] = 1  # Impulse at center\n",
    "        coeffs = scipy.ndimage.gaussian_filter1d(delta, sigma=sigma)\n",
    "        number_of_zeros = coeffs.size - np.count_nonzero(coeffs)\n",
    "        number_of_coeffs += 1\n",
    "    return coeffs[1:-1]  # Remove the first and last zero elements\n",
    "\n",
    "# Define parameters\n",
    "sigma_values = np.linspace(0.5, 10, 100)  # Range of sigma values to test\n",
    "N = 256  # Signal length\n",
    "normalized_cutoff_freqs = []\n",
    "\n",
    "for sigma in sigma_values:\n",
    "    # Generate Gaussian kernel\n",
    "    kernel = get_gaussian_kernel(sigma)\n",
    "\n",
    "    # Compute its frequency response\n",
    "    freq_response = np.abs(np.fft.fft(kernel, N))  # Compute FFT\n",
    "    freq_response = freq_response[:N//2]  # Take only the first half (positive frequencies)\n",
    "    freq_axis = np.linspace(0, 0.5, N//2)  # Normalized frequency axis (Nyquist = 0.5)\n",
    "\n",
    "    # Find the effective cut-off frequency (where magnitude falls below ~0.707)\n",
    "    cutoff_idx = np.where(freq_response < freq_response[0] / np.sqrt(2))[0][0]\n",
    "    cutoff_freq = freq_axis[cutoff_idx]\n",
    "    normalized_cutoff_freqs.append(cutoff_freq)\n",
    "\n",
    "# Fit an empirical formula: f_c^* ≈ C / sigma\n",
    "coeff = np.polyfit(1 / sigma_values, normalized_cutoff_freqs, 1)\n",
    "\n",
    "# Display empirical relationship\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(sigma_values, normalized_cutoff_freqs, 'bo-', label='Measured Cut-off')\n",
    "plt.plot(sigma_values, coeff[0] * (1 / sigma_values) + coeff[1], 'r--', label=f'Fit: {coeff[0]:.3f}/sigma + {coeff[1]:.3f}')\n",
    "plt.xlabel(\"Sigma\")\n",
    "plt.ylabel(r\"Effective Normalized Cut-off Frequency ($f_c^*$)\")\n",
    "plt.legend()\n",
    "plt.title(\"Empirical Relationship Between Sigma and Cut-off Frequency\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Empirical formula: f_c^* ≈ {coeff[0]:.3f} / sigma + {coeff[1]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_cutoff_to_tau(cutoff_freq):\n",
    "    tau = 0.158 / cutoff_freq\n",
    "    return tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = normalized_cutoff_to_tau(0.25)\n",
    "tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = np.array([tau, tau])\n",
    "kernel = [None]*2\n",
    "kernel[0] = utils.get_gaussian_kernel(sigma[0])\n",
    "kernel[1] = utils.get_gaussian_kernel(sigma[1])\n",
    "print(np.sum(kernel[0]))\n",
    "plt.plot(kernel[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised = denoiser.filter(Y, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq, c_avg_denoised = fsc.get_SFRC_curve(denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(freq, c_avg_Y)\n",
    "plt.plot(freq, c_avg_denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.imshow(denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSNR = IT.distortion.PSNR(denoised, X)\n",
    "PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string  = r\"$\\mathrm{GF}_{\\text{\"\n",
    "string += str(TAU)\n",
    "string += r\"}}(\\hat{\\mathbf{X}}_1)\"\n",
    "#string += r\"}}(\\mathrm{Barb} + \\mathbf{N}_{\\mathcal{N}\"\n",
    "#string += r\"(\\sigma\"\n",
    "#string += f\"={std_dev})\"\n",
    "#string += r'}'\n",
    "#string += r\" + \\mathbf{N}_{\\mathcal{P}\"\n",
    "#string += r\"(\\lambda\"\n",
    "#string += f\"={gamma}\"\n",
    "#string += r'\\cdot\\mathrm{Barb})}'\n",
    "#string += rf\"$_{(\\sigma^2={std_dev}^2)}$\"\n",
    "#string += f\"/{gamma})\"\n",
    "string += f\",~{IT.distortion.PSNR(Y1.astype(np.uint8), X1):.2f}\"\n",
    "string += r\"~\\text{dB}$\"\n",
    "plt.title(f\"{string}\")\n",
    "plt.imshow(denoised1, cmap=\"gray\")\n",
    "plt.savefig('GF_0MMPG_barb.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, h1 = signal.freqz(kernel[0], fs=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(w1, 20 * np.log10(abs(h1)), 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(w1, abs(h1), 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 0.5\n",
    "sigma = np.array([tau, tau])\n",
    "kernel = [None]*2\n",
    "kernel[0] = utils.get_gaussian_kernel(sigma[0])\n",
    "kernel[1] = utils.get_gaussian_kernel(sigma[1])\n",
    "print(np.sum(kernel[0]))\n",
    "plt.plot(kernel[0])\n",
    "plt.show()\n",
    "w1, h1 = signal.freqz(kernel[0], fs=10000)\n",
    "plt.plot(w1, abs(h1), 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 1.0\n",
    "sigma = np.array([tau, tau])\n",
    "kernel = [None]*2\n",
    "kernel[0] = utils.get_gaussian_kernel(sigma[0])\n",
    "kernel[1] = utils.get_gaussian_kernel(sigma[1])\n",
    "print(np.sum(kernel[0]))\n",
    "plt.plot(kernel[0])\n",
    "plt.show()\n",
    "w1, h1 = signal.freqz(kernel[0], fs=10000)\n",
    "plt.plot(w1, abs(h1), 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 1.5\n",
    "sigma = np.array([tau, tau])\n",
    "kernel = [None]*2\n",
    "kernel[0] = utils.get_gaussian_kernel(sigma[0])\n",
    "kernel[1] = utils.get_gaussian_kernel(sigma[1])\n",
    "print(np.sum(kernel[0]))\n",
    "plt.plot(kernel[0])\n",
    "plt.show()\n",
    "w1, h1 = signal.freqz(kernel[0], fs=10000)\n",
    "plt.plot(w1, abs(h1), 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 2.0\n",
    "sigma = np.array([tau, tau])\n",
    "kernel = [None]*2\n",
    "kernel[0] = utils.get_gaussian_kernel(sigma[0])\n",
    "kernel[1] = utils.get_gaussian_kernel(sigma[1])\n",
    "print(np.sum(kernel[0]))\n",
    "plt.plot(kernel[0])\n",
    "plt.show()\n",
    "w1, h1 = signal.freqz(kernel[0], fs=10000)\n",
    "plt.plot(w1, abs(h1), 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 2.5\n",
    "sigma = np.array([tau, tau])\n",
    "kernel = [None]*2\n",
    "kernel[0] = utils.get_gaussian_kernel(sigma[0])\n",
    "kernel[1] = utils.get_gaussian_kernel(sigma[1])\n",
    "print(np.sum(kernel[0]))\n",
    "plt.plot(kernel[0])\n",
    "plt.show()\n",
    "w1, h1 = signal.freqz(kernel[0], fs=10000)\n",
    "plt.plot(w1, abs(h1), 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 3.0\n",
    "sigma = np.array([tau, tau])\n",
    "kernel = [None]*2\n",
    "kernel[0] = utils.get_gaussian_kernel(sigma[0])\n",
    "kernel[1] = utils.get_gaussian_kernel(sigma[1])\n",
    "print(np.sum(kernel[0]))\n",
    "plt.plot(kernel[0])\n",
    "plt.show()\n",
    "w1, h1 = signal.freqz(kernel[0], fs=10000)\n",
    "plt.plot(w1, abs(h1), 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised2 = denoiser.filter(Y2, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSNR2 = IT.distortion.PSNR(denoised2, X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string  = r\"$\\mathrm{GF}_{\\text{\"\n",
    "string += str(TAU)\n",
    "string += r\"}}(\\hat{\\mathbf{X}}_2)\"\n",
    "#string += r\"}}(\\mathrm{Barb} + \\mathbf{N}_{\\mathcal{N}\"\n",
    "#string += r\"(\\sigma\"\n",
    "#string += f\"={std_dev})\"\n",
    "#string += r'}'\n",
    "#string += r\" + \\mathbf{N}_{\\mathcal{P}\"\n",
    "#string += r\"(\\lambda\"\n",
    "#string += f\"={gamma}\"\n",
    "#string += r'\\cdot\\mathrm{Barb})}'\n",
    "#string += rf\"$_{(\\sigma^2={std_dev}^2)}$\"\n",
    "#string += f\"/{gamma})\"\n",
    "string += f\",~{IT.distortion.PSNR(Y2.astype(np.uint8), X2):.2f}\"\n",
    "string += r\"~\\text{dB}$\"\n",
    "plt.title(f\"{string}\")\n",
    "plt.imshow(denoised2, cmap=\"gray\")\n",
    "plt.savefig('GF_0MMPG_lake.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GF_PCC_0MMPG_barb and GF_PCC_0MMPG_lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sigmas_kernel = [(0.2 + i/40) for i in range(40)] # Number of points per line\n",
    "#sigmas_kernel.append(0.625)\n",
    "#sigmas_kernel.sort()\n",
    "#sigmas_kernel = [0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0]\n",
    "std_devs = [i for i in range(0, 100, 20)]\n",
    "PCC_curves1 = []\n",
    "PCC_curves2 = []\n",
    "#SFRC_curves = []\n",
    "poisson_ratio = 0.5\n",
    "gamma = 0.15\n",
    "for std_dev in std_devs: # Number of noise levels\n",
    "    #gamma = std_dev / 50\n",
    "    PCC_curve1 = []\n",
    "    PCC_curve2 = []\n",
    "    #SFRC_curve = []\n",
    "    Y1 = utils.generate_MPGN(X1, std_dev, gamma, poisson_ratio).reshape(X1.shape)\n",
    "    Y2 = utils.generate_MPGN(X2, std_dev, gamma, poisson_ratio).reshape(X2.shape)\n",
    "    #Y = np.clip(a = Y, a_min=0, a_max=255) # Probar a quitar\n",
    "    #for sigma_kernel in range(5, 20, 1):\n",
    "    for sigma_kernel in sigmas_kernel: # Filter length\n",
    "        #sigma_kernel /= 10\n",
    "        sigma = np.array([sigma_kernel, sigma_kernel])\n",
    "        kernel = [None]*2\n",
    "        kernel[0] = utils.get_gaussian_kernel(sigma[0])\n",
    "        kernel[1] = utils.get_gaussian_kernel(sigma[1])\n",
    "        #print(\"Kernel:\", kernel)\n",
    "        denoised1 = denoiser.filter(Y1, kernel)\n",
    "        denoised2 = denoiser.filter(Y2, kernel)\n",
    "        #PSNR = IT.distortion.PSNR(denoised, X)\n",
    "        PCC1 = np.corrcoef(denoised1.flatten(), X1.flatten())[0, 1]\n",
    "        PCC2 = np.corrcoef(denoised2.flatten(), X2.flatten())[0, 1]\n",
    "        print(\"std_dev:\", std_dev, \"sigma_kernel:\", sigma_kernel, \"PCC1:\", PCC1, \"PCC2:\", PCC2)\n",
    "        PCC_curve1.append(PCC1)\n",
    "        PCC_curve2.append(PCC2)\n",
    "        #freq, c_avg = fsc.get_SFRC_curve(denoised)\n",
    "        #first_half = c_avg[:len(c_avg)>>1]\n",
    "        #SFRC_curve.append(first_half)\n",
    "        #plt.imshow(denoised, cmap=\"gray\")\n",
    "        #plt.show()\n",
    "        #input()\n",
    "\n",
    "    PCC_curves1.append(PCC_curve1)\n",
    "    PCC_curves2.append(PCC_curve2)\n",
    "    #SFRC_curves.append(SFRC_curve)\n",
    "    \n",
    "    #sigma_index += 1\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.title(r\"$\\mathbf{X}=\\mathrm{Barb}$\")\n",
    "#plt.title(r\"$\\mathbb{E}_{\\text{\" + str(iters) + r\"}}(\\mathbf{N}\" + rf\"/{_lambda}\" + r\"), \\mathbf{N}\\sim\\mathrm{Poisson}\" + rf\"(\\lambda={_lambda}\" + r\"\\mathrm{Barb})$\")\n",
    "#plt.title(\"Averaging Poisson noisy instances of \\\"Barb\\\"\")\n",
    "#for i in range(len(curves)):\n",
    "i = 0\n",
    "for std_dev in std_devs:\n",
    "    #plt.plot([i/10 for i in range(5, 20, 1)], curves[i], label=rf\"$\\sigma={10+i*5}, \\lambda={(10-i)/40}\\cdot\" + r\"\\mathrm{Barb}$\")\n",
    "    #if ((10+i*5) == 40) and ((10-i)/40 == 0.15):\n",
    "    #plt.plot(sigmas_kernel, curves[i], label=rf\"$\\sigma={10+i*5}, \\gamma={(10-i)/40}\" + r\", \\mathrm{argmax}_\\tau=\" + rf\"{sigmas_kernel[np.argmax(curves[i])]:.2f}$\", marker='o')\n",
    "    #else:\n",
    "    plt.plot(sigmas_kernel,\n",
    "        PCC_curves1[i],\n",
    "        label=rf\"$\\sigma={std_dev}, \\gamma={gamma}\"\n",
    "        + r\", \\tau^*=\"\n",
    "        + rf\"{sigmas_kernel[np.argmax(PCC_curves1[i])]:.2f}\"\n",
    "        + \"$\")\n",
    "    i += 1\n",
    "string  = r\"$\"\n",
    "string += r\"\\mathrm{PCC}\"\n",
    "string += r\"(\\mathbf{X}_1, \"\n",
    "string += r\"\\mathrm{GF}_\\tau\"\n",
    "string += r\"(\\mathbf{X}_1\"\n",
    "string += r\"+ \\mathbf{N}_{\\mathcal{N}\"\n",
    "string += r\"(\\sigma)}\"\n",
    "string += r\"+ \\mathbf{N}_\"\n",
    "string += r\"{\\mathcal{P}(\\gamma\\mathbf{X}_1)}/\\gamma))\"\n",
    "string += r\"$\"\n",
    "plt.ylabel(string)\n",
    "#plt.ylabel(r\"$\\mathrm{PCC}(\\mathbf{X}, \\hat{\\mathbf{X}})$\")\n",
    "plt.xlabel(r\"$\\tau$\")\n",
    "plt.legend()\n",
    "#plt.show()\n",
    "plt.savefig(\"GF_PCC_0MMPG_barb.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.title(r\"$\\mathbf{X}=\\mathrm{Barb}$\")\n",
    "#plt.title(r\"$\\mathbb{E}_{\\text{\" + str(iters) + r\"}}(\\mathbf{N}\" + rf\"/{_lambda}\" + r\"), \\mathbf{N}\\sim\\mathrm{Poisson}\" + rf\"(\\lambda={_lambda}\" + r\"\\mathrm{Barb})$\")\n",
    "#plt.title(\"Averaging Poisson noisy instances of \\\"Barb\\\"\")\n",
    "#for i in range(len(curves)):\n",
    "i = 0\n",
    "for std_dev in std_devs:\n",
    "    #plt.plot([i/10 for i in range(5, 20, 1)], curves[i], label=rf\"$\\sigma={10+i*5}, \\lambda={(10-i)/40}\\cdot\" + r\"\\mathrm{Barb}$\")\n",
    "    #if ((10+i*5) == 40) and ((10-i)/40 == 0.15):\n",
    "    #plt.plot(sigmas_kernel, curves[i], label=rf\"$\\sigma={10+i*5}, \\gamma={(10-i)/40}\" + r\", \\mathrm{argmax}_\\tau=\" + rf\"{sigmas_kernel[np.argmax(curves[i])]:.2f}$\", marker='o')\n",
    "    #else:\n",
    "    plt.plot(sigmas_kernel,\n",
    "        PCC_curves2[i],\n",
    "        label=rf\"$\\sigma={std_dev}, \\gamma={gamma}\"\n",
    "        + r\", \\tau^*=\"\n",
    "        + rf\"{sigmas_kernel[np.argmax(PCC_curves2[i])]:.2f}\"\n",
    "        + \"$\")\n",
    "    i += 1\n",
    "string  = r\"$\"\n",
    "string += r\"\\mathrm{PCC}\"\n",
    "string += r\"(\\mathbf{X}_2, \"\n",
    "string += r\"\\mathrm{GF}_\\tau\"\n",
    "string += r\"(\\mathbf{X}_2\"\n",
    "string += r\"+ \\mathbf{N}_{\\mathcal{N}\"\n",
    "string += r\"(\\sigma)}\"\n",
    "string += r\"+ \\mathbf{N}_\"\n",
    "string += r\"{\\mathcal{P}(\\gamma\\mathbf{X}_2)}/\\gamma))\"\n",
    "string += r\"$\"\n",
    "plt.ylabel(string)\n",
    "#plt.ylabel(r\"$\\mathrm{PCC}(\\mathbf{X}, \\hat{\\mathbf{X}})$\")\n",
    "plt.xlabel(r\"$\\tau$\")\n",
    "plt.legend()\n",
    "#plt.show()\n",
    "plt.savefig(\"GF_PCC_0MMPG_lake.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "gaussian_denoising.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
